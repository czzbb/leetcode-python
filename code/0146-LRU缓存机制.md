# 146. LRU缓存机制

**难度：Medium**

## 题目

原文链接：https://leetcode-cn.com/problems/lru-cache/

运用你所掌握的数据结构，设计和实现一个  LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。  
获取数据 get(key) - 如果关键字 (key) 存在于缓存中，则获取关键字的值（总是正数），否则返回 -1。  
写入数据 put(key, value) - 如果关键字已经存在，则变更其数据值；如果关键字不存在，则插入该组「关键字/值」。当缓存容量达到上限时，它应该在写入新数据之前删除最久未使用的数据值，从而为新的数据值留出空间。

**进阶:**  
你是否可以在 O(1) 时间复杂度内完成这两种操作？

**示例:**
```
LRUCache cache = new LRUCache( 2 /* 缓存容量 */ );

cache.put(1, 1);
cache.put(2, 2);
cache.get(1);       // 返回  1
cache.put(3, 3);    // 该操作会使得关键字 2 作废
cache.get(2);       // 返回 -1 (未找到)
cache.put(4, 4);    // 该操作会使得关键字 1 作废
cache.get(1);       // 返回 -1 (未找到)
cache.get(3);       // 返回  3
cache.get(4);       // 返回  4
```

## 思路
* 有先后顺序，且删除操作在 `O(1)`，因此考虑链表结构
* 又需要在 `O(1)` 时间复杂度内完成，因此考虑哈希表
* **哈希双向链表**
* 最近使用的节点靠近头，反之靠近尾
* 哈希表的`key`对应链表的`key`，`value`对应节点指针
* 使用双向链表是因为：删除节点时，需要用到节点的前后节点
* 双向链表中需要`key`是因为：当删除链表尾节点时，需要删除哈希表的值
* 代码`2`的编码逻辑更清晰点
## 代码
```python
class DLinkedNode:
    # 双向链表
    def __init__(self, key=0, value=0):
        self.key = key
        self.value = value
        self.prev = None
        self.next = None
class a146_LRUCache:
    def __init__(self, capacity: int):
        # 哈希表
        self.cache = dict()
        # 使用伪头部和伪尾部节点
        self.head = DLinkedNode()
        self.tail = DLinkedNode()
        self.head.next = self.tail
        self.tail.prev = self.head
        #
        self.capacity = capacity
        self.size = 0

    def get(self, key: int) -> int:
        if key not in self.cache:
            return -1
        # 如果 key 存在，先通过哈希表定位，再移到头部
        node = self.cache[key]
        self.moveToHead(node)
        return node.value

    def put(self, key: int, value: int) -> None:
        if key not in self.cache:
            # 如果 key 不存在，创建一个新的节点
            node = DLinkedNode(key, value)
            # 添加进哈希表
            self.cache[key] = node
            # 添加至双向链表的头部
            self.addToHead(node)
            self.size += 1
            if self.size > self.capacity:
                # 如果超出容量，删除双向链表的尾部节点
                removed = self.removeTail()
                # 删除哈希表中对应的项
                self.cache.pop(removed.key)
                self.size -= 1
        else:
            # 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node = self.cache[key]
            node.value = value
            self.moveToHead(node)

    def addToHead(self, node):
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node

    def removeNode(self, node):
        node.prev.next = node.next
        node.next.prev = node.prev

    def moveToHead(self, node):
        self.removeNode(node)
        self.addToHead(node)

    def removeTail(self):
        node = self.tail.prev
        self.removeNode(node)
        return node
```
```python
class BLink:
    def __init__(self, key=0, value=0):
        self.key = key
        self.value = value
        self.nextn = None
        self.pren = None
class a146__LRUCache:
    # 逻辑更清晰点，好理解
    # 依次写remove,removetail, put, get函数
    # 因为get函数就是先remove，再put
    def __init__(self, capacity: int):
        self.head = BLink()
        self.tail = BLink()
        self.head.nextn = self.tail
        self.tail.pren = self.head
        #
        self.capacity = capacity
        #
        self.cache = dict()

    def get(self, key: int) -> int:
        if key not in self.cache:return -1
        node = self.cache[key]
        # 将原节点移到头部
        self.remove(node.key)
        self.put(node.key, node.value)
        return node.value

    def put(self, key: int, value: int) -> None:
        if key in self.cache:
            self.remove(key)
        #
        if self.capacity == 0:
            self.removetail()
        node = BLink(key, value)
        node.nextn = self.head.nextn
        node.pren = self.head
        node.nextn.pren = node
        node.pren.nextn = node
        #
        self.cache[key] = node
        #
        self.capacity -= 1

    def remove(self, key):
        node = self.cache[key]
        #
        node.pren.nextn = node.nextn
        node.nextn.pren = node.pren
        #
        self.cache.pop(key)
        #
        self.capacity+=1

    def removetail(self):
        node = self.tail.pren
        key = node.key
        self.remove(key)
```
